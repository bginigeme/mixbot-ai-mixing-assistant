#!/usr/bin/env python3
"""
Audio Analysis Script

This script analyzes audio files to extract various metrics including:
- Duration
- Silence detection
- RMS (loudness)
- Tempo (BPM)
- Clipping detection

Usage: python audio_analyzer.py <audio_file_path>
"""

import sys
import argparse
import numpy as np
import librosa
import soundfile as sf
from typing import Tuple, List


def load_audio(file_path: str) -> Tuple[np.ndarray, int]:
    """
    Load audio file using librosa.
    
    Args:
        file_path: Path to the audio file
        
    Returns:
        Tuple of (audio_data, sample_rate)
    """
    try:
        # Load audio with librosa (automatically resamples to 22050 Hz)
        audio, sr = librosa.load(file_path, sr=None)
        return audio, sr
    except Exception as e:
        print(f"Error loading audio file: {e}")
        sys.exit(1)


def calculate_duration(audio: np.ndarray, sample_rate: int) -> float:
    """
    Calculate the duration of the audio track.
    
    Args:
        audio: Audio data array
        sample_rate: Sample rate in Hz
        
    Returns:
        Duration in seconds
    """
    return len(audio) / sample_rate


def detect_silence(audio: np.ndarray, sample_rate: int, 
                   threshold_db: float = -40.0, min_silence_duration: float = 0.1) -> List[Tuple[float, float]]:
    """
    Detect silence periods in the audio.
    
    Args:
        audio: Audio data array
        sample_rate: Sample rate in Hz
        threshold_db: Threshold in dB below which is considered silence
        min_silence_duration: Minimum duration (seconds) to be considered silence
        
    Returns:
        List of (start_time, end_time) tuples for silence periods
    """
    # Convert threshold from dB to linear scale
    threshold_linear = 10**(threshold_db / 20.0)
    
    # Calculate RMS in short windows
    window_size = int(0.01 * sample_rate)  # 10ms windows
    hop_size = window_size // 2
    
    rms_values = []
    for i in range(0, len(audio) - window_size, hop_size):
        window = audio[i:i + window_size]
        rms = np.sqrt(np.mean(window**2))
        rms_values.append(rms)
    
    # Find silence periods
    silence_periods = []
    in_silence = False
    silence_start = 0
    
    for i, rms in enumerate(rms_values):
        time = i * hop_size / sample_rate
        
        if rms < threshold_linear and not in_silence:
            silence_start = time
            in_silence = True
        elif rms >= threshold_linear and in_silence:
            silence_end = time
            if silence_end - silence_start >= min_silence_duration:
                silence_periods.append((silence_start, silence_end))
            in_silence = False
    
    # Handle case where audio ends in silence
    if in_silence:
        silence_end = len(audio) / sample_rate
        if silence_end - silence_start >= min_silence_duration:
            silence_periods.append((silence_start, silence_end))
    
    return silence_periods


def calculate_rms(audio: np.ndarray) -> Tuple[float, float]:
    """
    Calculate RMS (Root Mean Square) of the audio.
    
    Args:
        audio: Audio data array
        
    Returns:
        Tuple of (RMS in linear scale, RMS in dB)
    """
    rms_linear = np.sqrt(np.mean(audio**2))
    rms_db = 20 * np.log10(rms_linear) if rms_linear > 0 else -np.inf
    return rms_linear, rms_db


def estimate_tempo(audio: np.ndarray, sample_rate: int) -> Tuple[float, float]:
    """
    Estimate the tempo (BPM) of the audio.
    
    Args:
        audio: Audio data array
        sample_rate: Sample rate in Hz
        
    Returns:
        Tuple of (tempo, confidence)
    """
    try:
        # Use librosa's tempo estimation
        tempo, beats = librosa.beat.beat_track(y=audio, sr=sample_rate)
        return tempo, 0.8  # librosa doesn't return confidence, using default
    except Exception as e:
        print(f"Warning: Could not estimate tempo: {e}")
        return 0.0, 0.0


def detect_clipping(audio: np.ndarray, sample_rate: int) -> Tuple[bool, float, float]:
    """
    Detect if audio is likely clipped.
    
    Args:
        audio: Audio data array
        sample_rate: Sample rate in Hz
        
    Returns:
        Tuple of (is_clipped, peak_level_db, clipping_threshold)
    """
    # Calculate peak level
    peak_level = np.max(np.abs(audio))
    peak_level_db = 20 * np.log10(peak_level) if peak_level > 0 else -np.inf
    
    # Check for clipping (typically above -0.1 dB for digital audio)
    clipping_threshold = -0.1
    is_clipped = peak_level_db > clipping_threshold
    
    # Additional check: look for flat peaks (common sign of clipping)
    flat_peak_threshold = 0.99
    flat_peaks = np.sum(np.abs(audio) > flat_peak_threshold)
    flat_peak_ratio = flat_peaks / len(audio)
    
    # If more than 0.1% of samples are at peak, likely clipped
    if flat_peak_ratio > 0.001:
        is_clipped = True
    
    return is_clipped, peak_level_db, clipping_threshold


def generate_mix_feedback(rms_db: float, peak_level_db: float, is_clipped: bool, 
                         silence_periods: List[Tuple[float, float]], tempo: float, 
                         duration: float, silence_percentage: float) -> None:
    """
    Generate professional mixing and mastering feedback based on analysis results.
    
    Args:
        rms_db: RMS level in dB
        peak_level_db: Peak level in dB
        is_clipped: Whether clipping was detected
        silence_periods: List of silence period timestamps
        tempo: Estimated tempo in BPM
        duration: Total duration in seconds
        silence_percentage: Percentage of silence in the track
    """
    print("üìä ANALYSIS SUMMARY:")
    print(f"   ‚Ä¢ RMS Level: {rms_db:.1f} dB")
    print(f"   ‚Ä¢ Peak Level: {peak_level_db:.1f} dB")
    print(f"   ‚Ä¢ Dynamic Range: {peak_level_db - rms_db:.1f} dB")
    print(f"   ‚Ä¢ Tempo: {float(tempo):.0f} BPM")
    print(f"   ‚Ä¢ Silence: {silence_percentage:.1f}% of track")
    print()
    
    # Loudness and Dynamics Analysis
    print("üîä LOUDNESS & DYNAMICS:")
    if rms_db > -8:
        print("   ‚ö†Ô∏è  RMS is quite high - consider reducing overall level")
        print("      ‚Üí Lower your master fader by 2-3 dB")
        print("      ‚Üí Check if individual tracks are too loud")
    elif rms_db < -16:
        print("   ‚ÑπÔ∏è  RMS is quite low - you have headroom for mastering")
        print("      ‚Üí Consider gentle compression to bring up quiet parts")
        print("      ‚Üí Ensure your mix translates well on different systems")
    else:
        print("   ‚úÖ RMS level is in a good range for mastering")
    
    if peak_level_db > -1:
        print("   ‚ö†Ô∏è  Peak level is very close to clipping")
        print("      ‚Üí Reduce peak levels by 1-2 dB")
        print("      ‚Üí Check for transients that need taming")
    elif peak_level_db < -6:
        print("   ‚ÑπÔ∏è  Peak level has good headroom")
        print("      ‚Üí You can safely increase overall level if needed")
    
    dynamic_range = peak_level_db - rms_db
    if dynamic_range > 15:
        print("   ‚ÑπÔ∏è  Large dynamic range detected")
        print("      ‚Üí Consider compression to control dynamics")
        print("      ‚Üí Check if quiet parts are getting lost")
    elif dynamic_range < 6:
        print("   ‚ö†Ô∏è  Very compressed/limited sound")
        print("      ‚Üí Back off on compression/limiting")
        print("      ‚Üí Allow more natural dynamics")
    
    print()
    
    # Clipping Analysis
    print("üéöÔ∏è CLIPPING & DISTORTION:")
    if is_clipped:
        print("   ‚ùå CLIPPING DETECTED - IMMEDIATE ACTION NEEDED:")
        print("      ‚Üí Reduce master fader by 3-5 dB")
        print("      ‚Üí Check individual tracks for clipping")
        print("      ‚Üí Use a limiter with -1 dB ceiling")
        print("      ‚Üí Consider using soft clipping for character")
    else:
        print("   ‚úÖ No clipping detected - good headroom management")
    
    print()
    
    # Silence and Structure Analysis
    print("‚è±Ô∏è TIMING & STRUCTURE:")
    if silence_percentage > 10:
        print(f"   ‚ÑπÔ∏è  High silence content ({silence_percentage:.1f}%)")
        print("      ‚Üí Consider if long gaps serve the song")
        print("      ‚Üí Add subtle ambience to fill empty spaces")
        print("      ‚Üí Check if sections flow well together")
    elif silence_percentage < 2:
        print("   ‚ÑπÔ∏è  Very dense arrangement")
        print("      ‚Üí Consider adding breathing room")
        print("      ‚Üí Let important elements shine")
    
    if silence_periods:
        longest_silence = max(end - start for start, end in silence_periods)
        if longest_silence > 5:
            print(f"   ‚ö†Ô∏è  Long silence detected ({longest_silence:.1f}s)")
            print("      ‚Üí Consider if this serves the song")
            print("      ‚Üí Add subtle elements to maintain interest")
    
    print()
    
    # Tempo and Rhythm Analysis
    print("üéµ TEMPO & RHYTHM:")
    if tempo > 0:
        if tempo < 80:
            print("   ‚ÑπÔ∏è  Slow tempo - focus on groove and feel")
            print("      ‚Üí Ensure timing is tight")
            print("      ‚Üí Consider subtle swing or groove")
        elif tempo > 160:
            print("   ‚ÑπÔ∏è  Fast tempo - clarity is key")
            print("      ‚Üí Ensure each element has space")
            print("      ‚Üí Consider side-chain compression")
        else:
            print("   ‚úÖ Tempo is in a good range for most genres")
    
    print()
    
    # Specific Recommendations
    print("üéõÔ∏è SPECIFIC RECOMMENDATIONS:")
    
    # EQ suggestions based on common issues
    print("   EQ Suggestions:")
    print("      ‚Üí High-pass filter at 20-30 Hz to remove rumble")
    print("      ‚Üí Cut 200-400 Hz if mix sounds muddy")
    print("      ‚Üí Boost 2-4 kHz for presence and clarity")
    print("      ‚Üí High-shelf 8-12 kHz for air and brightness")
    
    # Compression suggestions
    print("   Compression:")
    if dynamic_range > 12:
        print("      ‚Üí Use gentle compression (2:1 ratio) to control dynamics")
    print("      ‚Üí Consider parallel compression for thickness")
    print("      ‚Üí Use side-chain compression to create space")
    
    # Reverb and effects
    print("   Effects:")
    print("      ‚Üí Add subtle reverb to glue elements together")
    print("      ‚Üí Use delay to create space and movement")
    print("      ‚Üí Consider saturation for warmth and character")
    
    print()
    
    # Mastering preparation
    print("üéöÔ∏è MASTERING PREPARATION:")
    print("   ‚Üí Leave 1-2 dB headroom for mastering engineer")
    print("   ‚Üí Ensure mix translates on different speakers")
    print("   ‚Üí Check mono compatibility")
    print("   ‚Üí Consider using reference tracks for comparison")
    
    print()
    print("üí° Remember: These are guidelines - trust your ears!")
    print("   The best mix is the one that serves the song.")


def analyze_audio(file_path: str) -> None:
    """
    Perform comprehensive audio analysis.
    
    Args:
        file_path: Path to the audio file
    """
    print(f"Analyzing audio file: {file_path}")
    print("=" * 50)
    
    # Load audio
    audio, sample_rate = load_audio(file_path)
    
    # 1. Calculate duration
    duration = calculate_duration(audio, sample_rate)
    print(f"Duration: {duration:.2f} seconds ({duration/60:.2f} minutes)")
    
    # 2. Detect silence
    silence_periods = detect_silence(audio, sample_rate)
    total_silence_time = sum(end - start for start, end in silence_periods)
    silence_percentage = (total_silence_time / duration) * 100
    
    print(f"Silence Detection:")
    print(f"  - Total silence time: {total_silence_time:.2f} seconds ({silence_percentage:.1f}%)")
    print(f"  - Number of silence periods: {len(silence_periods)}")
    if silence_periods:
        print(f"  - Silence periods: {silence_periods[:5]}")  # Show first 5 periods
        if len(silence_periods) > 5:
            print(f"    ... and {len(silence_periods) - 5} more")
    
    # 3. Calculate RMS
    rms_linear, rms_db = calculate_rms(audio)
    print(f"RMS (Loudness):")
    print(f"  - Linear: {rms_linear:.6f}")
    print(f"  - dB: {rms_db:.2f} dB")
    
    # 4. Estimate tempo
    tempo, confidence = estimate_tempo(audio, sample_rate)
    if tempo > 0:
        print(f"Tempo: {float(tempo):.1f} BPM (confidence: {float(confidence):.2f})")
    else:
        print("Tempo: Could not be estimated")
    
    # 5. Detect clipping
    is_clipped, peak_level_db, clipping_threshold = detect_clipping(audio, sample_rate)
    print(f"Clipping Detection:")
    print(f"  - Peak level: {peak_level_db:.2f} dB")
    print(f"  - Clipping threshold: {clipping_threshold:.2f} dB")
    print(f"  - Likely clipped: {'YES' if is_clipped else 'NO'}")
    
    # Additional metrics
    print(f"\nAdditional Metrics:")
    print(f"  - Sample rate: {sample_rate} Hz")
    print(f"  - Number of samples: {len(audio):,}")
    print(f"  - Dynamic range: {peak_level_db - rms_db:.2f} dB")
    
    # 6. Generate mixing and mastering feedback
    print(f"\n" + "=" * 50)
    print("üéµ MIXING & MASTERING FEEDBACK")
    print("=" * 50)
    generate_mix_feedback(rms_db, peak_level_db, is_clipped, silence_periods, 
                         tempo, duration, silence_percentage)


def main():
    """Main function to handle command line arguments and run analysis."""
    parser = argparse.ArgumentParser(
        description="Analyze audio files for duration, silence, RMS, tempo, and clipping",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python audio_analyzer.py song.wav
  python audio_analyzer.py music.mp3
        """
    )
    
    parser.add_argument(
        "audio_file",
        help="Path to the audio file to analyze (.wav, .mp3, etc.)"
    )
    
    args = parser.parse_args()
    
    # Check if file exists
    import os
    if not os.path.exists(args.audio_file):
        print(f"Error: File '{args.audio_file}' not found.")
        sys.exit(1)
    
    # Perform analysis
    analyze_audio(args.audio_file)


if __name__ == "__main__":
    main() 